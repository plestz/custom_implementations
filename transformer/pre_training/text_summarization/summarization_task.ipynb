{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f8197d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "48e3952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the parent directory (i.e. project root)\n",
    "project_root = Path().resolve().parent.parent \n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "from tokenization.byte_pair_encoding.get_tokenizers import train_and_save_tokenizer_for, load_tokenizer_from\n",
    "\n",
    "from pre_training.text_summarization.dataset import TextSummarizationDataset\n",
    "\n",
    "from src.embedding import CustomEmbedding\n",
    "from src.transformer import EncoderDecoderTransformer\n",
    "from src.utils import padding_collate_fn\n",
    "\n",
    "from src.train_utils import run_train_epoch\n",
    "from src.validation_utils import run_gold_validation_loop, run_autoregressive_validation_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "81921cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_DATA_PATH = '../../data/SAMSum/'\n",
    "\n",
    "BPE_IN_PATH = '../../data/SAMSum/train_summary_and_dialogue.txt'\n",
    "BPE_OUT_PATH = '../../tokenization/trained_tokenizers/SAMSum_BPE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0a22ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONTEXT_WINDOW = 100\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "D_MODEL = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "73f11a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(DF_DATA_PATH + 'train_df.json', orient = 'records', lines = True)\n",
    "val_df = pd.read_json(DF_DATA_PATH + 'val_df.json', orient = 'records', lines = True)\n",
    "test_df = pd.read_json(DF_DATA_PATH + 'test_df.json', orient = 'records', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "319eede3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "The vocab size is 4000.\n",
      "The pad token index is 2.\n"
     ]
    }
   ],
   "source": [
    "bpe_tokenizer = train_and_save_tokenizer_for(in_file_paths = [BPE_IN_PATH], out_file_dir_path = BPE_OUT_PATH, vocab_size = 4_000)\n",
    "pretrained_bpe_tokenizer = load_tokenizer_from(dir_path = BPE_OUT_PATH, model_max_length = 10000)\n",
    "\n",
    "VOCAB_SIZE = pretrained_bpe_tokenizer.vocab_size\n",
    "PAD_TOKEN_IDX = pretrained_bpe_tokenizer.pad_token_id\n",
    "\n",
    "print(f'The vocab size is {VOCAB_SIZE}.')\n",
    "print(f'The pad token index is {PAD_TOKEN_IDX}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fbc2c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = CustomEmbedding(VOCAB_SIZE, D_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5747ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_prefix_space(texts: list[str]):\n",
    "    return [' ' + text.lstrip() for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8a000cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a max_context_window of 100...\n",
      "The number of training samples went from 14732 to 5561\n",
      "The number of validation samples went from 818 to 325\n",
      "The number of test samples went from 819 to 306\n"
     ]
    }
   ],
   "source": [
    "FILTER_tokenized_train_sources = pretrained_bpe_tokenizer(\n",
    "    normalize_prefix_space(train_df['dialogue'].tolist()),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "FILTER_tokenized_train_targets = pretrained_bpe_tokenizer(\n",
    "    ('<SOS> ' + train_df['summary']).tolist(),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "FILTER_tokenized_val_sources = pretrained_bpe_tokenizer(\n",
    "    normalize_prefix_space(val_df['dialogue'].tolist()),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "FILTER_tokenized_val_targets = pretrained_bpe_tokenizer(\n",
    "    ('<SOS> ' + val_df['summary']).tolist(),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "FILTER_tokenized_test_sources = pretrained_bpe_tokenizer(\n",
    "    normalize_prefix_space(test_df['dialogue'].tolist()),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "FILTER_tokenized_test_targets = pretrained_bpe_tokenizer(\n",
    "    ('<SOS> ' + test_df['summary']).tolist(),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "valid_src_train_indices = np.array([len(example) <= MAX_CONTEXT_WINDOW for example in FILTER_tokenized_train_sources.data['input_ids']])\n",
    "valid_src_val_indices = np.array([len(example) <= MAX_CONTEXT_WINDOW for example in FILTER_tokenized_val_sources.data['input_ids']])\n",
    "valid_src_test_indices = np.array([len(example) <= MAX_CONTEXT_WINDOW for example in FILTER_tokenized_test_sources.data['input_ids']])\n",
    "\n",
    "valid_tgt_train_indices = np.array([len(example) <= MAX_CONTEXT_WINDOW for example in FILTER_tokenized_train_targets.data['input_ids']])\n",
    "valid_tgt_val_indices = np.array([len(example) <= MAX_CONTEXT_WINDOW for example in FILTER_tokenized_val_targets.data['input_ids']])\n",
    "valid_tgt_test_indices = np.array([len(example) <= MAX_CONTEXT_WINDOW for example in FILTER_tokenized_test_targets.data['input_ids']])\n",
    "\n",
    "valid_train_df = train_df.iloc[valid_src_train_indices & valid_tgt_train_indices]\n",
    "valid_val_df = val_df.iloc[valid_src_val_indices & valid_tgt_val_indices]\n",
    "valid_test_df = test_df.iloc[valid_src_test_indices & valid_tgt_test_indices]\n",
    "\n",
    "print(f'With a max_context_window of {MAX_CONTEXT_WINDOW}...')\n",
    "print(f'The number of training samples went from {train_df.shape[0]} to {valid_train_df.shape[0]}')\n",
    "print(f'The number of validation samples went from {val_df.shape[0]} to {valid_val_df.shape[0]}')\n",
    "print(f'The number of test samples went from {test_df.shape[0]} to {valid_test_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "686aeb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sources = pretrained_bpe_tokenizer(\n",
    "    normalize_prefix_space(valid_train_df['dialogue'].tolist()),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "tokenized_train_targets = pretrained_bpe_tokenizer(\n",
    "    ('<SOS> ' + valid_train_df['summary']).tolist(),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "tokenized_train_labels = pretrained_bpe_tokenizer(\n",
    "    normalize_prefix_space((valid_train_df['summary'] + '<EOS>').tolist()),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "tokenized_val_sources = pretrained_bpe_tokenizer(\n",
    "    normalize_prefix_space(valid_val_df['dialogue'].tolist()),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "tokenized_val_targets = pretrained_bpe_tokenizer(\n",
    "    ('<SOS> ' + valid_val_df['summary']).tolist(),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "tokenized_val_labels = pretrained_bpe_tokenizer(\n",
    "    normalize_prefix_space((valid_val_df['summary'] + '<EOS>').tolist()),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "tokenized_test_sources = pretrained_bpe_tokenizer(\n",
    "    normalize_prefix_space(valid_test_df['dialogue'].tolist()),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "tokenized_test_targets = pretrained_bpe_tokenizer(\n",
    "    ('<SOS> ' + valid_test_df['summary']).tolist(),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")\n",
    "\n",
    "tokenized_test_labels = pretrained_bpe_tokenizer(\n",
    "    normalize_prefix_space((valid_test_df['summary'] + '<EOS>').tolist()),\n",
    "    add_special_tokens = False,\n",
    "    return_attention_mask = False,\n",
    "    return_token_type_ids = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "28756f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TextSummarizationDataset(tokenized_train_sources.data['input_ids'], tokenized_train_targets.data['input_ids'], tokenized_train_labels.data['input_ids'])\n",
    "val_ds = TextSummarizationDataset(tokenized_val_sources.data['input_ids'], tokenized_val_targets.data['input_ids'], tokenized_val_labels.data['input_ids'])\n",
    "test_ds = TextSummarizationDataset(tokenized_test_sources.data['input_ids'], tokenized_test_targets.data['input_ids'], tokenized_test_labels.data['input_ids'])\n",
    "\n",
    "# NOTE: Option to use HuggingFace DataCollatorWithPadding : requires changing TextSummarizationDataset __getitem__\n",
    "train_dataloader = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = True, collate_fn = partial(padding_collate_fn, pad_token_idx = PAD_TOKEN_IDX))\n",
    "val_dataloader = DataLoader(val_ds, batch_size = BATCH_SIZE, collate_fn = partial(padding_collate_fn, pad_token_idx = PAD_TOKEN_IDX))\n",
    "test_dataloader = DataLoader(test_ds, batch_size = BATCH_SIZE, collate_fn = partial(padding_collate_fn, pad_token_idx = PAD_TOKEN_IDX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f5508a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1868,  270,   30,  ...,    2,    2,    2],\n",
      "        [ 525, 1831,   30,  ...,    2,    2,    2],\n",
      "        [1798,   30,  488,  ...,    2,    2,    2],\n",
      "        ...,\n",
      "        [ 367, 1078,   30,  ...,    2,    2,    2],\n",
      "        [ 393,  627,   74,  ...,    2,    2,    2],\n",
      "        [1818,  334,   30,  ...,    2,    2,    2]])\n",
      "tensor([[   0, 1868,  270,  ...,    2,    2,    2],\n",
      "        [   0,  461,  738,  ...,    2,    2,    2],\n",
      "        [   0, 1798,  785,  ...,    2,    2,    2],\n",
      "        ...,\n",
      "        [   0, 1365, 3535,  ...,    2,    2,    2],\n",
      "        [   0, 2572,   73,  ...,    2,    2,    2],\n",
      "        [   0, 1818,  334,  ...,    2,    2,    2]])\n",
      "tensor([[1868,  270,  309,  ...,    2,    2,    2],\n",
      "        [ 461,  738,  314,  ...,    2,    2,    2],\n",
      "        [1798,  785,  280,  ...,    2,    2,    2],\n",
      "        ...,\n",
      "        [1365, 3535,  785,  ...,    2,    2,    2],\n",
      "        [2572,   73,  323,  ...,    2,    2,    2],\n",
      "        [1818,  334, 1339,  ...,    2,    2,    2]])\n"
     ]
    }
   ],
   "source": [
    "(source, target), label = next(iter(train_dataloader))\n",
    "print(source)\n",
    "print(target)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9399cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_IDX, reduction = 'sum')\n",
    "\n",
    "model = EncoderDecoderTransformer(\n",
    "    embeddings = embeddings,\n",
    "    vocab_size = VOCAB_SIZE,\n",
    "    d_model = D_MODEL,\n",
    "    num_attention_heads = 4,\n",
    "    num_encoder_layers = 1,\n",
    "    num_decoder_layers = 1,\n",
    "    dim_feedforward = 32,\n",
    "    dropout = 0.0,\n",
    "    max_context_window = MAX_CONTEXT_WINDOW,\n",
    "    use_pre_lnorm = True\n",
    ")\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr = 1e-4, momentum = 0.9, weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d0ddd08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5/87 [00:00<00:07, 10.67it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (2624) to match target batch_size (2560).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[219]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m gold_validation_token_accuracies = \u001b[38;5;28mlist\u001b[39m()\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# print(f'Running epoch {i+1}...')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     training_loss, training_sequence_accuracy, training_token_accuracy = \u001b[43mrun_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_sequence_accuracy\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_token_accuracy\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     training_losses.append(training_loss)\n\u001b[32m     17\u001b[39m     training_sequence_accuracies.append(training_sequence_accuracy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:23\u001b[39m, in \u001b[36mrun_train_epoch\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer, calculate_sequence_accuracy, calculate_token_accuracy)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/loss.py:1179\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/env/lib/python3.12/site-packages/torch/nn/functional.py:3059\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3058\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3059\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Expected input batch_size (2624) to match target batch_size (2560)."
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "training_losses = list()\n",
    "training_sequence_accuracies = list()\n",
    "training_token_accuracies = list()\n",
    "\n",
    "gold_validation_losses = list()\n",
    "gold_validation_sequence_accuracies = list()\n",
    "gold_validation_token_accuracies = list()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    # print(f'Running epoch {i+1}...')\n",
    "\n",
    "    training_loss, training_sequence_accuracy, training_token_accuracy = run_train_epoch(train_dataloader, model, loss_fn, optim, calculate_sequence_accuracy = True, calculate_token_accuracy = True)\n",
    "\n",
    "    training_losses.append(training_loss)\n",
    "    training_sequence_accuracies.append(training_sequence_accuracy)\n",
    "    training_token_accuracies.append(training_token_accuracy)\n",
    "\n",
    "    gold_val_loss, gold_val_sequence_accuracy, gold_val_token_accuracy = run_gold_validation_loop(val_dataloader, model, loss_fn, calculate_sequence_accuracy = True, calculate_token_accuracy = True)\n",
    "    \n",
    "    gold_validation_losses.append(gold_val_loss)\n",
    "    gold_validation_sequence_accuracies.append(gold_val_sequence_accuracy)\n",
    "    gold_validation_token_accuracies.append(gold_val_token_accuracy)\n",
    "\n",
    "print(training_losses)\n",
    "print(training_sequence_accuracies)\n",
    "print(training_token_accuracies)\n",
    "\n",
    "print()\n",
    "\n",
    "print(gold_validation_losses)\n",
    "print(gold_validation_sequence_accuracies)\n",
    "print(gold_validation_token_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
