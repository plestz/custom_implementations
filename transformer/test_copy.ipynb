{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from functools import partial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "from embedding import CustomEmbedding\n",
    "from transformer import EncoderDecoderTransformer\n",
    "from utils import padding_collate_fn\n",
    "import numpy as np\n",
    "\n",
    "from generate_data import RandomIntegerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5448,  0.5140, -0.0046, -1.5803,  0.1601, -1.9841, -0.0121,  0.9440,\n",
      "         -0.6594, -0.5013,  0.6966, -0.2668,  0.1034, -0.7649,  0.3096,  0.1248,\n",
      "          2.9369,  0.5064, -1.1475, -1.3232, -0.2540,  0.5299,  1.5605, -1.1508,\n",
      "          1.3092,  0.8036, -1.2186,  1.0163, -0.6580,  1.3856,  0.1441, -0.9281],\n",
      "        [-1.5278, -1.5359, -0.1916,  0.1813, -0.9562, -1.3280,  0.1115, -1.7997,\n",
      "          0.3175, -0.2955,  1.0714, -0.1378,  0.5252,  0.8031, -1.9382, -1.2450,\n",
      "          0.3134, -1.9736, -0.8155,  0.2727, -0.0506, -1.1737, -0.1022, -0.8935,\n",
      "          1.4556,  0.2721,  0.8885,  0.6084, -0.3604, -0.9189,  1.3727, -0.2031]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_real_tokens = 10\n",
    "PAD_TOKEN_IDX = n_real_tokens\n",
    "SOS_TOKEN_IDX = n_real_tokens + 1\n",
    "EOS_TOKEN_IDX = n_real_tokens + 2\n",
    "vocab_size = n_real_tokens + 3\n",
    "D_MODEL = 32\n",
    "\n",
    "embeddings = CustomEmbedding(vocab_size, d_model = D_MODEL) # 3 = PAD, SOS, EOS\n",
    "\n",
    "indices = torch.tensor([1,9])\n",
    "\n",
    "# print(embeddings.embeddings.weight)\n",
    "print(embeddings.embeddings(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONTEXT_WINDOW = 50\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MIN_SEQ_LEN = 2\n",
    "MAX_SEQ_LEN = min(10, MAX_CONTEXT_WINDOW)\n",
    "\n",
    "NUM_TRAINING_SEQUENCES = 10000\n",
    "NUM_VALIDATION_SEQUENCES = 1000\n",
    "\n",
    "VOCAB = [i for i in range(n_real_tokens)] # does not include SOS, EOS, PAD\n",
    "\n",
    "VOCAB_MAP = dict()\n",
    "\n",
    "for i, token in enumerate(VOCAB):\n",
    "    VOCAB_MAP[i] = token\n",
    "VOCAB_MAP[len(VOCAB_MAP)] = '<PAD>'\n",
    "VOCAB_MAP[len(VOCAB_MAP) + 1] = '<SOS>'\n",
    "VOCAB_MAP[len(VOCAB_MAP) + 2] = '<EOS>'\n",
    "\n",
    "train_rand_ds = RandomIntegerDataset(MIN_SEQ_LEN, MAX_SEQ_LEN, NUM_TRAINING_SEQUENCES, VOCAB)\n",
    "train_dataloader = DataLoader(train_rand_ds, batch_size = BATCH_SIZE, shuffle = True, collate_fn = partial(padding_collate_fn, pad_token_idx = PAD_TOKEN_IDX))\n",
    "\n",
    "val_rand_ds = RandomIntegerDataset(MIN_SEQ_LEN, MAX_SEQ_LEN, NUM_VALIDATION_SEQUENCES, VOCAB)\n",
    "val_dataloader = DataLoader(val_rand_ds, batch_size = BATCH_SIZE, collate_fn = partial(padding_collate_fn, pad_token_idx = PAD_TOKEN_IDX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  4, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 5,  7,  0,  0,  9,  8,  4, 10, 10, 10],\n",
      "        [ 3,  9,  3,  1,  4,  7,  1,  3, 10, 10],\n",
      "        [ 6,  8, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 5,  8, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 3,  3, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 5,  0,  4,  1,  2,  8,  2,  9,  8,  4],\n",
      "        [ 0,  8,  1,  7, 10, 10, 10, 10, 10, 10],\n",
      "        [ 8,  5,  7,  1,  4,  0,  5, 10, 10, 10],\n",
      "        [ 8,  2,  5,  6,  8,  7,  5,  8, 10, 10],\n",
      "        [ 6,  7,  3,  3,  0,  4,  5,  7,  8, 10],\n",
      "        [ 6,  8, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  0, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 4,  7,  8,  0, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  8,  4,  9, 10, 10, 10, 10, 10, 10],\n",
      "        [ 5,  6,  1,  7, 10, 10, 10, 10, 10, 10],\n",
      "        [ 1,  6,  1,  0,  1,  0,  4,  6,  4, 10],\n",
      "        [ 9,  0,  4, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 7,  5,  5,  9,  5,  1,  8,  1,  8, 10],\n",
      "        [ 1,  3,  3,  2,  2, 10, 10, 10, 10, 10],\n",
      "        [ 1,  5,  2, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 6,  6,  0,  3, 10, 10, 10, 10, 10, 10],\n",
      "        [ 9,  7,  4,  9,  5,  0,  1, 10, 10, 10],\n",
      "        [ 4,  4,  8,  9,  1,  3,  6,  4,  4, 10],\n",
      "        [ 1,  1, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 7,  3,  5,  9,  5,  7,  3,  7,  9, 10],\n",
      "        [ 7,  0,  1,  2,  3,  8,  2,  0,  5,  2],\n",
      "        [ 3,  1, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 2,  0,  4,  0,  5,  7,  0,  0,  2,  1],\n",
      "        [ 7,  9,  7,  0, 10, 10, 10, 10, 10, 10],\n",
      "        [ 1,  1,  4,  9,  4,  8,  9,  4, 10, 10],\n",
      "        [ 7,  9,  1,  3,  7,  2,  1,  8, 10, 10]])\n",
      "tensor([[11,  0,  4, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  0,  4,  5,  7,  8,  9, 10, 10, 10],\n",
      "        [11,  1,  1,  3,  3,  3,  4,  7,  9, 10, 10],\n",
      "        [11,  6,  8, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  5,  8, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  3,  3, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  1,  2,  2,  4,  4,  5,  8,  8,  9],\n",
      "        [11,  0,  1,  7,  8, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  1,  4,  5,  5,  7,  8, 10, 10, 10],\n",
      "        [11,  2,  5,  5,  6,  7,  8,  8,  8, 10, 10],\n",
      "        [11,  0,  3,  3,  4,  5,  6,  7,  7,  8, 10],\n",
      "        [11,  6,  8, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  0, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  4,  7,  8, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  4,  8,  9, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  1,  5,  6,  7, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  0,  1,  1,  1,  4,  4,  6,  6, 10],\n",
      "        [11,  0,  4,  9, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  1,  1,  5,  5,  5,  7,  8,  8,  9, 10],\n",
      "        [11,  1,  2,  2,  3,  3, 10, 10, 10, 10, 10],\n",
      "        [11,  1,  2,  5, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  3,  6,  6, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  1,  4,  5,  7,  9,  9, 10, 10, 10],\n",
      "        [11,  1,  3,  4,  4,  4,  4,  6,  8,  9, 10],\n",
      "        [11,  1,  1, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  3,  3,  5,  5,  7,  7,  7,  9,  9, 10],\n",
      "        [11,  0,  0,  1,  2,  2,  2,  3,  5,  7,  8],\n",
      "        [11,  1,  3, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  0,  0,  0,  0,  1,  2,  2,  4,  5,  7],\n",
      "        [11,  0,  7,  7,  9, 10, 10, 10, 10, 10, 10],\n",
      "        [11,  1,  1,  4,  4,  4,  8,  9,  9, 10, 10],\n",
      "        [11,  1,  1,  2,  3,  7,  7,  8,  9, 10, 10]])\n",
      "tensor([[ 0,  4, 12, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  0,  4,  5,  7,  8,  9, 12, 10, 10, 10],\n",
      "        [ 1,  1,  3,  3,  3,  4,  7,  9, 12, 10, 10],\n",
      "        [ 6,  8, 12, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 5,  8, 12, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 3,  3, 12, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  1,  2,  2,  4,  4,  5,  8,  8,  9, 12],\n",
      "        [ 0,  1,  7,  8, 12, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  1,  4,  5,  5,  7,  8, 12, 10, 10, 10],\n",
      "        [ 2,  5,  5,  6,  7,  8,  8,  8, 12, 10, 10],\n",
      "        [ 0,  3,  3,  4,  5,  6,  7,  7,  8, 12, 10],\n",
      "        [ 6,  8, 12, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  0, 12, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  4,  7,  8, 12, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  4,  8,  9, 12, 10, 10, 10, 10, 10, 10],\n",
      "        [ 1,  5,  6,  7, 12, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  0,  1,  1,  1,  4,  4,  6,  6, 12, 10],\n",
      "        [ 0,  4,  9, 12, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 1,  1,  5,  5,  5,  7,  8,  8,  9, 12, 10],\n",
      "        [ 1,  2,  2,  3,  3, 12, 10, 10, 10, 10, 10],\n",
      "        [ 1,  2,  5, 12, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  3,  6,  6, 12, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  1,  4,  5,  7,  9,  9, 12, 10, 10, 10],\n",
      "        [ 1,  3,  4,  4,  4,  4,  6,  8,  9, 12, 10],\n",
      "        [ 1,  1, 12, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 3,  3,  5,  5,  7,  7,  7,  9,  9, 12, 10],\n",
      "        [ 0,  0,  1,  2,  2,  2,  3,  5,  7,  8, 12],\n",
      "        [ 1,  3, 12, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "        [ 0,  0,  0,  0,  1,  2,  2,  4,  5,  7, 12],\n",
      "        [ 0,  7,  7,  9, 12, 10, 10, 10, 10, 10, 10],\n",
      "        [ 1,  1,  4,  4,  4,  8,  9,  9, 12, 10, 10],\n",
      "        [ 1,  1,  2,  3,  7,  7,  8,  9, 12, 10, 10]])\n"
     ]
    }
   ],
   "source": [
    "input, label = next(iter(train_dataloader))\n",
    "print(input[0])\n",
    "print(input[1])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_IDX, reduction = 'sum')\n",
    "\n",
    "model = EncoderDecoderTransformer(\n",
    "                    embeddings = embeddings, \n",
    "                    vocab_size = vocab_size, \n",
    "                    d_model = D_MODEL, \n",
    "                    num_attention_heads = 4, \n",
    "                    num_encoder_layers = 1, \n",
    "                    num_decoder_layers = 1, \n",
    "                    dim_feedforward = 32, \n",
    "                    dropout = 0.0,\n",
    "                    max_context_window = MAX_CONTEXT_WINDOW,\n",
    "                    use_pre_lnorm = True)\n",
    "\n",
    "optim = torch.optim.SGD(params = model.parameters(), lr = 1e-3, momentum = 0.9, weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(source: torch.Tensor, model: nn.Module) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Designed to do autoregressive inference in an Encoder-Decoder transformer.\n",
    "\n",
    "    This greedy decoder always predicts the vocabulary token corresponding to the highest logit.\n",
    "\n",
    "    Takes the source sequence and the Encoder-Decoder to produce a predicted\n",
    "    sequence starting from <SOS>.\n",
    "\n",
    "    Note: This function *can* handle batches of sequences.\n",
    "\n",
    "    Args:\n",
    "        source - The source sequence to be passed to the Transformer's encoder block.\n",
    "        model - The Encoder-Decoder transformer over which to greedy decode\n",
    "\n",
    "    Returns:\n",
    "        target - The batch of predicted sequences corresponding to the input sources.\n",
    "        target_logits - (# batch elements =) batch_size (# rows =) seq_len (# cols =) vocab-dimensional vectors, each of which\n",
    "        corresponds to the set of logits on a particular inference step within a given sequence.\n",
    "    \"\"\"\n",
    "    batch_size = source.size(dim = 0)\n",
    "\n",
    "    encoder_output, source_pad_mask = model.encode(source)\n",
    "\n",
    "    # target will contain num_batch sequences of indices that are the predicted next-words for each batch element\n",
    "    target = torch.full((batch_size, 1), SOS_TOKEN_IDX) # target.shape: [batch_size, num_loops_complete - 1]\n",
    "    target_logits = torch.zeros((batch_size, 1, vocab_size))\n",
    "\n",
    "    finished = torch.full((batch_size, ), False)\n",
    "\n",
    "    while not finished.all() and target.size(dim = 1) <= MAX_CONTEXT_WINDOW:\n",
    "\n",
    "        decoder_output, _ = model.decode(target, encoder_output, source_pad_mask)\n",
    "        pred_logits = model.project_into_vocab(decoder_output) # pred_logits.shape: [batch_size, seq_len, vocab_size]\n",
    "\n",
    "        last_row_pred_logits = pred_logits[:, -1, :] # last_row_pred_logits.shape == [batch_size, vocab_size]\n",
    "\n",
    "        # Track next-word logits for loss_fn later.\n",
    "        target_logits = torch.concat((target_logits, last_row_pred_logits.unsqueeze(1)), dim = 1)\n",
    "\n",
    "        predictions = torch.argmax(last_row_pred_logits, dim = -1) # predictions.shape: [batch_size]\n",
    "\n",
    "        # For any finished sequences (i.e. previous EOS-producers), force their prediction from this round to be a pad.\n",
    "        predictions[finished] = PAD_TOKEN_IDX\n",
    "\n",
    "        # Mark any additional sequences that just produced an EOS as finished.\n",
    "        finished |= predictions == EOS_TOKEN_IDX\n",
    "\n",
    "        target = torch.concat((target, predictions.reshape(-1, 1)), dim = 1) # target.shape: [batch_size, num_loops_complete]\n",
    "\n",
    "    return target, target_logits[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_epoch(dataloader: DataLoader, model: nn.Module, loss_fn: nn.Module, optimizer: torch.optim.Optimizer, calculate_sequence_accuracy: bool = False, calculate_token_accuracy: bool = False):\n",
    "    \"\"\"\n",
    "    Runs one training epoch (processing the entire training dataset once).\n",
    "    \n",
    "    Uses Teacher Forcing to train token-to-token mapping quality without cascading errors and for parallelization.\n",
    "\n",
    "    Args:\n",
    "        dataloader - The dataloader to process the dataset in BATCH_SIZE batches\n",
    "        model - The Encoder-Decoder that is being trained\n",
    "        loss_fn - The loss function to calculate the model's correctness\n",
    "        optimizer - The optimizer to improve the model's weights\n",
    "        calculate_sequence_accuracy - A flag to mark whether sequence-level correctness should be tracked\n",
    "        calculate_token_accuracy - A flag to mark whether token-level correctness should be tracked\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    num_sequences = len(dataloader.dataset)\n",
    "    num_tokens = 0\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    total_correct_sequences = 0\n",
    "    total_correct_tokens = 0\n",
    "\n",
    "    for (source, target), label in tqdm(dataloader):\n",
    "\n",
    "        # FORWARD\n",
    "        pred_logits = model(source, target)\n",
    "\n",
    "        # pred_logits.shape: [batch_size, seq_len, vocab_size]\n",
    "        # label.shape: [batch_size, seq_len]\n",
    "\n",
    "        # CrossEntropyLoss (loss_fn) only takes 2D predictions (n_batch * seq_len, vocab_size) and 1D labels (n_batch * seq_len)\n",
    "        batch_loss = loss_fn(pred_logits.view(-1, pred_logits.size(-1)), label.view(-1))\n",
    "\n",
    "        # LOG\n",
    "        with torch.no_grad():\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            predictions = torch.argmax(pred_logits, dim = -1) # predictions.shape: [batch_size, seq_len]\n",
    "            match_matrix = torch.eq(predictions, label)\n",
    "\n",
    "            if calculate_sequence_accuracy:\n",
    "                num_correct_sequences = torch.all(match_matrix, dim = 1).sum()\n",
    "                total_correct_sequences += num_correct_sequences.item()\n",
    "\n",
    "            if calculate_token_accuracy:\n",
    "                num_correct_tokens = match_matrix.sum()      \n",
    "                total_correct_tokens += num_correct_tokens.item()\n",
    "\n",
    "                num_tokens += torch.numel(label)\n",
    "\n",
    "        # BACKWARD\n",
    "        batch_loss.backward()\n",
    "\n",
    "        # OPTIMIZE\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    average_epoch_loss = epoch_loss / num_sequences\n",
    "    average_epoch_sequence_accuracy = total_correct_sequences / num_sequences if calculate_sequence_accuracy else None\n",
    "    average_epoch_token_accuracy = total_correct_tokens / num_tokens if calculate_token_accuracy else None\n",
    "\n",
    "    return average_epoch_loss, average_epoch_sequence_accuracy, average_epoch_token_accuracy\n",
    "\n",
    "def run_gold_validation_loop(dataloader: DataLoader, model: nn.Module, loss_fn: nn.Module, calculate_sequence_accuracy: bool = False, calculate_token_accuracy: bool = False):\n",
    "    \"\"\"\n",
    "    Runs one validation epoch (processing the entire validation dataset once). \n",
    "\n",
    "    Uses Teacher Forcing (i.e. \"gold\") to evaluate token-to-token mapping quality and for parallelization.\n",
    "\n",
    "    Args:\n",
    "        dataloader - The dataloader to process the dataset in BATCH_SIZE batches\n",
    "        model - The Encoder-Decoder that is being trained\n",
    "        loss_fn - The loss function to calculate the model's correctness\n",
    "        calculate_sequence_accuracy - A flag to mark whether sequence-level correctness should be tracked\n",
    "        calculate_token_accuracy - A flag to mark whether token-level correctness should be tracked\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    num_sequences = len(dataloader.dataset)\n",
    "    num_tokens = 0\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    total_correct_sequences = 0\n",
    "    total_correct_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (source, target), label in tqdm(dataloader):\n",
    "            \n",
    "            # FORWARD\n",
    "            pred_logits = model(source, target)\n",
    "            batch_loss = loss_fn(pred_logits.view(-1, pred_logits.size(-1)), label.view(-1))\n",
    "\n",
    "            # LOG\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            predictions = torch.argmax(pred_logits, dim = -1) # predictions.shape: [batch_size, seq_len]\n",
    "            match_matrix = torch.eq(predictions, label)\n",
    "\n",
    "            if calculate_sequence_accuracy:\n",
    "                num_correct_sequences = torch.all(match_matrix, dim = 1).sum()\n",
    "                total_correct_sequences += num_correct_sequences.item()\n",
    "\n",
    "            if calculate_token_accuracy:\n",
    "                num_correct_tokens = match_matrix.sum()      \n",
    "                total_correct_tokens += num_correct_tokens.item()\n",
    "\n",
    "                num_tokens += torch.numel(label)\n",
    "\n",
    "    average_epoch_loss = epoch_loss / num_sequences\n",
    "    average_epoch_sequence_accuracy = total_correct_sequences / num_sequences if calculate_sequence_accuracy else None\n",
    "    average_epoch_token_accuracy = total_correct_tokens / num_tokens if calculate_token_accuracy else None\n",
    "\n",
    "    return average_epoch_loss, average_epoch_sequence_accuracy, average_epoch_token_accuracy\n",
    "\n",
    "def run_autoregressive_validation_loop(dataloader: DataLoader, model: nn.Module):\n",
    "    \"\"\"\n",
    "    Runs one autoregressive validation epoch (processing the entire validation dataset once). \n",
    "\n",
    "    Args:\n",
    "        dataloader - The dataloader to process the dataset in BATCH_SIZE batches\n",
    "        model - The Encoder-Decoder that is being trained\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (source, _), label in tqdm(dataloader):\n",
    "\n",
    "            # FORWARD\n",
    "            pred_indices, pred_logits = greedy_decode(source, model)\n",
    "\n",
    "            np_source_indices = source.numpy().copy()\n",
    "            np_pred_target_indices = pred_indices.numpy().copy()\n",
    "\n",
    "            token_values = np.array(list(VOCAB_MAP.values()))\n",
    "            predicted_source_tokens = token_values[np_source_indices]\n",
    "            predicted_target_tokens = token_values[np_pred_target_indices]\n",
    "\n",
    "            for s, t in zip(predicted_source_tokens, predicted_target_tokens):\n",
    "                print(f'Source: {s} | Predicted Target: {t}', end = '\\n\\n')\n",
    "\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ['6' '4' '3' '5' '1' '0' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['0' '9' '1' '8' '2' '5' '2' '7' '3' '6'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['0' '9' '8' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['0' '9' '1' '0' '1' '5' '0' '5' '2' '2'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['9' '9' '5' '8' '4' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['4' '3' '3' '5' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['2' '3' '6' '8' '8' '1' '2' '1' '4' '2'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['0' '2' '5' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['3' '0' '0' '2' '6' '2' '8' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['3' '9' '9' '4' '9' '7' '6' '5' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['6' '9' '1' '1' '4' '1' '4' '8' '7' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['6' '5' '3' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '5' '2' '3' '6' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['6' '2' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '5' '2' '3' '6' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['5' '4' '4' '0' '1' '2' '7' '6' '2' '8'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['4' '6' '6' '9' '8' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '5' '2' '3' '6' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['2' '8' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['7' '6' '6' '5' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '5' '2' '3' '6' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['8' '3' '6' '3' '7' '6' '4' '0' '1' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['2' '3' '8' '1' '4' '6' '8' '8' '1' '7'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['8' '1' '1' '1' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['7' '0' '7' '0' '5' '8' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['5' '2' '9' '2' '9' '5' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['9' '0' '4' '1' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['6' '9' '1' '4' '8' '4' '6' '1' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['4' '7' '3' '7' '0' '5' '8' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['4' '3' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['6' '9' '1' '3' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['4' '7' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '5' '2' '3' '6' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['3' '3' '8' '1' '9' '1' '0' '7' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['9' '5' '4' '3' '0' '7' '9' '2' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['5' '8' '6' '3' '7' '1' '8' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['2' '2' '6' '0' '4' '9' '2' '5' '0' '<PAD>'] | Predicted Target: ['<SOS>' '<SOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_autoregressive_validation_loop(val_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 111.54it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 308.86it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 117.96it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 314.16it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 121.49it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 314.74it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 119.48it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 287.76it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 118.17it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 308.23it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 118.10it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 297.21it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 117.24it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 303.40it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 117.27it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 309.97it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 120.14it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 303.04it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 119.28it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 311.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.4198414722442627, 1.978666478538513, 1.7790723428726196, 1.3568450530052185, 1.4800289199829102, 1.523850697374344, 1.3325836317062378, 1.0960996666908265, 1.0303833721160889, 1.0317252554178238]\n",
      "[0.0082, 0.0224, 0.0269, 0.0375, 0.0334, 0.0367, 0.0412, 0.0493, 0.0499, 0.0565]\n",
      "[0.5215859431900947, 0.5710678868309756, 0.57920125236639, 0.5912530927084849, 0.5890358548316572, 0.588587986586966, 0.5944924209298936, 0.6017982072584172, 0.6044250693127098, 0.6068198395331874]\n",
      "\n",
      "[1.9810250482559204, 1.8635208463668824, 1.8278143348693847, 1.5377175226211548, 2.2769010972976687, 1.4479214429855347, 1.8263604469299317, 1.837783058166504, 0.791296683549881, 4.017484312057495]\n",
      "[0.031, 0.018, 0.005, 0.022, 0.01, 0.027, 0.02, 0.013, 0.06, 0.005]\n",
      "[0.5734170305676856, 0.5765101892285298, 0.5695960698689956, 0.5852438136826783, 0.5610443959243085, 0.5877001455604076, 0.5694141193595342, 0.5833333333333334, 0.6108078602620087, 0.5211062590975255]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "training_losses = list()\n",
    "training_sequence_accuracies = list()\n",
    "training_token_accuracies = list()\n",
    "\n",
    "gold_validation_losses = list()\n",
    "gold_validation_sequence_accuracies = list()\n",
    "gold_validation_token_accuracies = list()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    # print(f'Running epoch {i+1}...')\n",
    "\n",
    "    training_loss, training_sequence_accuracy, training_token_accuracy = run_train_epoch(train_dataloader, model, loss_fn, optim, calculate_sequence_accuracy = True, calculate_token_accuracy = True)\n",
    "\n",
    "    training_losses.append(training_loss)\n",
    "    training_sequence_accuracies.append(training_sequence_accuracy)\n",
    "    training_token_accuracies.append(training_token_accuracy)\n",
    "\n",
    "    gold_val_loss, gold_val_sequence_accuracy, gold_val_token_accuracy = run_gold_validation_loop(val_dataloader, model, loss_fn, calculate_sequence_accuracy = True, calculate_token_accuracy = True)\n",
    "    gold_validation_losses.append(gold_val_loss)\n",
    "    gold_validation_sequence_accuracies.append(gold_val_sequence_accuracy)\n",
    "    gold_validation_token_accuracies.append(gold_val_token_accuracy)\n",
    "\n",
    "print(training_losses)\n",
    "print(training_sequence_accuracies)\n",
    "print(training_token_accuracies)\n",
    "\n",
    "print()\n",
    "\n",
    "print(gold_validation_losses)\n",
    "print(gold_validation_sequence_accuracies)\n",
    "print(gold_validation_token_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ['6' '4' '3' '5' '1' '0' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '0' '1' '3' '4' '5' '6' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>']\n",
      "\n",
      "Source: ['0' '9' '1' '8' '2' '5' '2' '7' '3' '6'] | Predicted Target: ['<SOS>' '0' '0' '1' '2' '2' '3' '6' '7' '8' '8' '9' '<EOS>']\n",
      "\n",
      "Source: ['0' '9' '8' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '0' '8' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['0' '9' '1' '0' '1' '5' '0' '5' '2' '2'] | Predicted Target: ['<SOS>' '0' '0' '0' '0' '0' '1' '2' '5' '8' '9' '<EOS>' '<PAD>']\n",
      "\n",
      "Source: ['9' '9' '5' '8' '4' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '4' '5' '8' '9' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['4' '3' '3' '5' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '3' '3' '4' '4' '5' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['2' '3' '6' '8' '8' '1' '2' '1' '4' '2'] | Predicted Target: ['<SOS>' '1' '2' '2' '3' '4' '6' '8' '8' '8' '<EOS>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['0' '2' '5' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '0' '2' '5' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['3' '0' '0' '2' '6' '2' '8' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '0' '0' '2' '3' '8' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['3' '9' '9' '4' '9' '7' '6' '5' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '3' '4' '6' '7' '9' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>']\n",
      "\n",
      "Source: ['6' '9' '1' '1' '4' '1' '4' '8' '7' '<PAD>'] | Predicted Target: ['<SOS>' '1' '1' '3' '4' '4' '6' '7' '8' '9' '<EOS>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['6' '5' '3' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '3' '6' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['6' '2' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '2' '6' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['5' '4' '4' '0' '1' '2' '7' '6' '2' '8'] | Predicted Target: ['<SOS>' '0' '0' '1' '2' '4' '4' '6' '7' '8' '8' '<EOS>' '<PAD>']\n",
      "\n",
      "Source: ['4' '6' '6' '9' '8' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '4' '6' '6' '8' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['2' '8' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '2' '8' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['7' '6' '6' '5' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '5' '6' '6' '7' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['8' '3' '6' '3' '7' '6' '4' '0' '1' '<PAD>'] | Predicted Target: ['<SOS>' '0' '1' '3' '3' '4' '6' '7' '8' '<EOS>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['2' '3' '8' '1' '4' '6' '8' '8' '1' '7'] | Predicted Target: ['<SOS>' '1' '1' '2' '3' '4' '6' '7' '8' '8' '8' '<EOS>' '<PAD>']\n",
      "\n",
      "Source: ['8' '1' '1' '1' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '1' '1' '8' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['7' '0' '7' '0' '5' '8' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '0' '0' '0' '7' '8' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['5' '2' '9' '2' '9' '5' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '2' '2' '5' '9' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['9' '0' '4' '1' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '0' '1' '4' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['6' '9' '1' '4' '8' '4' '6' '1' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '1' '1' '4' '6' '6' '8' '8' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['4' '7' '3' '7' '0' '5' '8' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '0' '0' '3' '4' '7' '7' '8' '8' '<EOS>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['4' '3' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '3' '4' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['6' '9' '1' '3' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '1' '3' '6' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['4' '7' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '4' '7' '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['3' '3' '8' '1' '9' '1' '0' '7' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '0' '1' '3' '7' '8' '8' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>']\n",
      "\n",
      "Source: ['9' '5' '4' '3' '0' '7' '9' '2' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '0' '0' '2' '3' '4' '7' '9' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n",
      "Source: ['5' '8' '6' '3' '7' '1' '8' '<PAD>' '<PAD>' '<PAD>'] | Predicted Target: ['<SOS>' '1' '3' '6' '7' '8' '8' '8' '<EOS>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>']\n",
      "\n",
      "Source: ['2' '2' '6' '0' '4' '9' '2' '5' '0' '<PAD>'] | Predicted Target: ['<SOS>' '0' '0' '2' '0' '4' '5' '6' '8' '9' '<EOS>' '<PAD>' '<PAD>']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_autoregressive_validation_loop(val_dataloader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
