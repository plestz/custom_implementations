{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511c828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a7d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/opt/miniconda3/envs/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from get_tokenizers import train_and_save_tokenizer_for, load_tokenizer_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7dfa9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZES = [i * 1000 for i in range(1, 21)]\n",
    "MIN_FREQUENCY = 2\n",
    "\n",
    "IN_PATH = '../../data/SAMSum/train_summary_and_dialogue.txt'\n",
    "OUT_DIR_PATH = '../trained_tokenizers/SAMSum_BPE/elbow/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df87cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "1000\n",
      "\n",
      "\n",
      "\n",
      "2000\n",
      "\n",
      "\n",
      "\n",
      "3000\n",
      "\n",
      "\n",
      "\n",
      "4000\n",
      "\n",
      "\n",
      "\n",
      "5000\n",
      "\n",
      "\n",
      "\n",
      "6000\n",
      "\n",
      "\n",
      "\n",
      "7000\n",
      "\n",
      "\n",
      "\n",
      "8000\n",
      "\n",
      "\n",
      "\n",
      "9000\n",
      "\n",
      "\n",
      "\n",
      "10000\n",
      "\n",
      "\n",
      "\n",
      "11000\n",
      "\n",
      "\n",
      "\n",
      "12000\n",
      "\n",
      "\n",
      "\n",
      "13000\n",
      "\n",
      "\n",
      "\n",
      "14000\n",
      "\n",
      "\n",
      "\n",
      "15000\n",
      "\n",
      "\n",
      "\n",
      "16000\n",
      "\n",
      "\n",
      "\n",
      "17000\n",
      "\n",
      "\n",
      "\n",
      "18000\n",
      "\n",
      "\n",
      "\n",
      "19000\n",
      "\n",
      "\n",
      "\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "for vocab_size in VOCAB_SIZES:\n",
    "\n",
    "    bpe_tokenizer = train_and_save_tokenizer_for(in_file_paths = [IN_PATH], out_file_dir_path = OUT_DIR_PATH, vocab_size = vocab_size, min_frequency = MIN_FREQUENCY)\n",
    "    pretrained_bpe_tokenizer = load_tokenizer_from(dir_path = OUT_DIR_PATH)\n",
    "\n",
    "    print(pretrained_bpe_tokenizer.vocab_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
