{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from functools import partial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "from embedding import CustomEmbedding\n",
    "from transformer import EncoderDecoderTransformer\n",
    "from utils import padding_collate_fn\n",
    "import numpy as np\n",
    "\n",
    "from generate_data import RandomIntegerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.5912, -1.4263, -0.4131, -0.4404, -0.6530, -0.0486, -0.5205,  0.0795,\n",
      "         -0.3692,  1.3514, -1.7537,  1.6198, -0.6558, -0.6826, -0.1505,  0.1238,\n",
      "          1.8447, -0.0927,  0.6445,  0.1265, -0.6074, -1.6156, -1.3574,  0.2402,\n",
      "          1.1803,  1.2475,  0.0982,  0.6528, -1.1838,  1.1011, -0.7063, -1.6845,\n",
      "         -0.0553,  0.0330,  1.1433, -0.2270,  1.4425, -1.8413,  1.0542, -0.3801,\n",
      "          0.2648, -2.4542,  0.0830,  1.9601,  0.2750, -0.5426,  1.0269,  1.7440,\n",
      "         -2.4217,  0.3061,  0.5601, -1.4078,  0.3974,  0.2823, -1.2763, -1.0821,\n",
      "         -0.0217,  0.6498,  0.8835,  0.3206, -0.0731, -0.1787, -1.3928,  1.1576],\n",
      "        [-0.0983,  2.7286,  1.7257, -0.4248, -1.6255, -1.6202,  0.8901,  0.6736,\n",
      "         -1.3352,  0.2541, -1.3306, -0.9637,  0.1807, -0.7534, -0.6530,  1.9191,\n",
      "         -0.9400, -0.5747, -1.5215,  0.5857, -1.7653,  1.7890, -0.1325, -0.0090,\n",
      "         -2.3319,  1.8486, -1.4751,  0.8222, -0.7151, -1.6365,  0.3117,  1.3396,\n",
      "         -0.6446,  0.7574,  0.7255, -0.3178, -0.2507,  0.0575,  0.3739, -0.2915,\n",
      "          0.4724,  1.4833,  1.3175, -1.0660,  0.7193,  1.2194, -1.0948,  0.9518,\n",
      "          0.1582, -0.2545,  1.6917,  1.2737, -2.0518, -0.1506,  1.4233, -2.7779,\n",
      "          0.8364, -1.1262,  0.4532, -0.6063,  0.2728, -0.3855, -0.1892,  0.0359]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_real_tokens = 10\n",
    "PAD_TOKEN_IDX = n_real_tokens\n",
    "SOS_TOKEN_IDX = n_real_tokens + 1\n",
    "EOS_TOKEN_IDX = n_real_tokens + 2\n",
    "vocab_size = n_real_tokens + 3\n",
    "D_MODEL = 64\n",
    "\n",
    "embeddings = CustomEmbedding(vocab_size, d_model = D_MODEL) # 3 = PAD, SOS, EOS\n",
    "\n",
    "indices = torch.tensor([1,9])\n",
    "\n",
    "# print(embeddings.embeddings.weight)\n",
    "print(embeddings.embeddings(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONTEXT_WINDOW = 50\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MIN_SEQ_LEN = 2\n",
    "MAX_SEQ_LEN = min(20, MAX_CONTEXT_WINDOW)\n",
    "\n",
    "NUM_TRAINING_SEQUENCES = 10000\n",
    "NUM_VALIDATION_SEQUENCES = 1000\n",
    "\n",
    "VOCAB = [i for i in range(n_real_tokens)] # does not include SOS, EOS, PAD\n",
    "\n",
    "VOCAB_MAP = dict()\n",
    "\n",
    "for i, token in enumerate(VOCAB):\n",
    "    VOCAB_MAP[i] = token\n",
    "VOCAB_MAP[len(VOCAB_MAP)] = '<PAD>'\n",
    "VOCAB_MAP[len(VOCAB_MAP) + 1] = '<SOS>'\n",
    "VOCAB_MAP[len(VOCAB_MAP) + 2] = '<EOS>'\n",
    "\n",
    "train_rand_ds = RandomIntegerDataset(MIN_SEQ_LEN, MAX_SEQ_LEN, NUM_TRAINING_SEQUENCES, VOCAB)\n",
    "train_dataloader = DataLoader(train_rand_ds, batch_size = BATCH_SIZE, shuffle = True, collate_fn = partial(padding_collate_fn, pad_token_idx = PAD_TOKEN_IDX))\n",
    "\n",
    "val_rand_ds = RandomIntegerDataset(MIN_SEQ_LEN, MAX_SEQ_LEN, NUM_VALIDATION_SEQUENCES, VOCAB)\n",
    "val_dataloader = DataLoader(val_rand_ds, batch_size = BATCH_SIZE, collate_fn = partial(padding_collate_fn, pad_token_idx = PAD_TOKEN_IDX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  4,  0,  ..., 10, 10, 10],\n",
      "        [ 9,  4,  3,  ..., 10, 10, 10],\n",
      "        [ 4,  5,  0,  ...,  9,  5,  1],\n",
      "        ...,\n",
      "        [ 6,  5,  6,  ..., 10, 10, 10],\n",
      "        [ 7,  0,  5,  ..., 10, 10, 10],\n",
      "        [ 4,  4,  1,  ..., 10, 10, 10]])\n",
      "tensor([[11,  0,  0,  ..., 10, 10, 10],\n",
      "        [11,  3,  3,  ..., 10, 10, 10],\n",
      "        [11,  0,  0,  ...,  9,  9,  9],\n",
      "        ...,\n",
      "        [11,  0,  1,  ..., 10, 10, 10],\n",
      "        [11,  0,  0,  ..., 10, 10, 10],\n",
      "        [11,  0,  1,  ..., 10, 10, 10]])\n",
      "tensor([[ 0,  0,  1,  ..., 10, 10, 10],\n",
      "        [ 3,  3,  4,  ..., 10, 10, 10],\n",
      "        [ 0,  0,  0,  ...,  9,  9, 12],\n",
      "        ...,\n",
      "        [ 0,  1,  2,  ..., 10, 10, 10],\n",
      "        [ 0,  0,  2,  ..., 10, 10, 10],\n",
      "        [ 0,  1,  4,  ..., 10, 10, 10]])\n"
     ]
    }
   ],
   "source": [
    "input, label = next(iter(train_dataloader))\n",
    "print(input[0])\n",
    "print(input[1])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/opt/miniconda3/envs/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_IDX, reduction = 'sum')\n",
    "\n",
    "model = EncoderDecoderTransformer(\n",
    "                    embeddings = embeddings, \n",
    "                    vocab_size = vocab_size, \n",
    "                    d_model = D_MODEL, \n",
    "                    num_attention_heads = 4, \n",
    "                    num_encoder_layers = 2, \n",
    "                    num_decoder_layers = 2, \n",
    "                    dim_feedforward = 32, \n",
    "                    dropout = 0.0,\n",
    "                    max_context_window = MAX_CONTEXT_WINDOW,\n",
    "                    use_pre_lnorm = True)\n",
    "\n",
    "optim = torch.optim.SGD(params = model.parameters(), lr = 1e-4, momentum = 0.9, weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(source: torch.Tensor, model: nn.Module) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Designed to do autoregressive inference in an Encoder-Decoder transformer.\n",
    "\n",
    "    This greedy decoder always predicts the vocabulary token corresponding to the highest logit.\n",
    "\n",
    "    Takes the source sequence and the Encoder-Decoder to produce a predicted\n",
    "    sequence starting from <SOS>.\n",
    "\n",
    "    Note: This function *can* handle batches of sequences.\n",
    "\n",
    "    Args:\n",
    "        source - The source sequence to be passed to the Transformer's encoder block.\n",
    "        model - The Encoder-Decoder transformer over which to greedy decode\n",
    "\n",
    "    Returns:\n",
    "        target - The batch of predicted sequences corresponding to the input sources.\n",
    "        target_logits - (# batch elements =) batch_size (# rows =) seq_len (# cols =) vocab-dimensional vectors, each of which\n",
    "        corresponds to the set of logits on a particular inference step within a given sequence.\n",
    "    \"\"\"\n",
    "    batch_size = source.size(dim = 0)\n",
    "\n",
    "    encoder_output, source_pad_mask = model.encode(source)\n",
    "\n",
    "    # target will contain num_batch sequences of indices that are the predicted next-words for each batch element\n",
    "    target = torch.full((batch_size, 1), SOS_TOKEN_IDX) # target.shape: [batch_size, num_loops_complete - 1]\n",
    "    target_logits = torch.zeros((batch_size, 1, vocab_size))\n",
    "\n",
    "    finished = torch.full((batch_size, ), False)\n",
    "\n",
    "    while not finished.all() and target.size(dim = 1) <= MAX_CONTEXT_WINDOW:\n",
    "\n",
    "        decoder_output, _ = model.decode(target, encoder_output, source_pad_mask)\n",
    "        pred_logits = model.project_into_vocab(decoder_output) # pred_logits.shape: [batch_size, seq_len, vocab_size]\n",
    "\n",
    "        last_row_pred_logits = pred_logits[:, -1, :] # last_row_pred_logits.shape == [batch_size, vocab_size]\n",
    "\n",
    "        # Track next-word logits for loss_fn later.\n",
    "        target_logits = torch.concat((target_logits, last_row_pred_logits.unsqueeze(1)), dim = 1)\n",
    "\n",
    "        predictions = torch.argmax(last_row_pred_logits, dim = -1) # predictions.shape: [batch_size]\n",
    "\n",
    "        # For any finished sequences (i.e. previous EOS-producers), force their prediction from this round to be a pad.\n",
    "        predictions[finished] = PAD_TOKEN_IDX\n",
    "\n",
    "        # Mark any additional sequences that just produced an EOS as finished.\n",
    "        finished |= predictions == EOS_TOKEN_IDX\n",
    "\n",
    "        target = torch.concat((target, predictions.reshape(-1, 1)), dim = 1) # target.shape: [batch_size, num_loops_complete]\n",
    "\n",
    "    return target, target_logits[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_epoch(dataloader: DataLoader, model: nn.Module, loss_fn: nn.Module, optimizer: torch.optim.Optimizer, calculate_sequence_accuracy: bool = False, calculate_token_accuracy: bool = False):\n",
    "    \"\"\"\n",
    "    Runs one training epoch (processing the entire training dataset once).\n",
    "    \n",
    "    Uses Teacher Forcing to train token-to-token mapping quality without cascading errors and for parallelization.\n",
    "\n",
    "    Args:\n",
    "        dataloader - The dataloader to process the dataset in BATCH_SIZE batches\n",
    "        model - The Encoder-Decoder that is being trained\n",
    "        loss_fn - The loss function to calculate the model's correctness\n",
    "        optimizer - The optimizer to improve the model's weights\n",
    "        calculate_sequence_accuracy - A flag to mark whether sequence-level correctness should be tracked\n",
    "        calculate_token_accuracy - A flag to mark whether token-level correctness should be tracked\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    num_sequences = len(dataloader.dataset)\n",
    "    num_tokens = 0\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    total_correct_sequences = 0\n",
    "    total_correct_tokens = 0\n",
    "\n",
    "    for (source, target), label in tqdm(dataloader):\n",
    "\n",
    "        # FORWARD\n",
    "        pred_logits = model(source, target)\n",
    "\n",
    "        # pred_logits.shape: [batch_size, seq_len, vocab_size]\n",
    "        # label.shape: [batch_size, seq_len]\n",
    "\n",
    "        # CrossEntropyLoss (loss_fn) only takes 2D predictions (n_batch * seq_len, vocab_size) and 1D labels (n_batch * seq_len)\n",
    "        batch_loss = loss_fn(pred_logits.view(-1, pred_logits.size(-1)), label.view(-1))\n",
    "\n",
    "        # LOG\n",
    "        with torch.no_grad():\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            predictions = torch.argmax(pred_logits, dim = -1) # predictions.shape: [batch_size, seq_len]\n",
    "            match_matrix = torch.eq(predictions, label)\n",
    "\n",
    "            if calculate_sequence_accuracy:\n",
    "                num_correct_sequences = torch.all(match_matrix, dim = 1).sum()\n",
    "                total_correct_sequences += num_correct_sequences.item()\n",
    "\n",
    "            if calculate_token_accuracy:\n",
    "                num_correct_tokens = match_matrix.sum()      \n",
    "                total_correct_tokens += num_correct_tokens.item()\n",
    "\n",
    "                num_tokens += torch.numel(label)\n",
    "\n",
    "        # BACKWARD\n",
    "        batch_loss.backward()\n",
    "\n",
    "        # OPTIMIZE\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    average_epoch_loss = epoch_loss / num_sequences\n",
    "    average_epoch_sequence_accuracy = total_correct_sequences / num_sequences if calculate_sequence_accuracy else None\n",
    "    average_epoch_token_accuracy = total_correct_tokens / num_tokens if calculate_token_accuracy else None\n",
    "\n",
    "    return average_epoch_loss, average_epoch_sequence_accuracy, average_epoch_token_accuracy\n",
    "\n",
    "def run_gold_validation_loop(dataloader: DataLoader, model: nn.Module, loss_fn: nn.Module, calculate_sequence_accuracy: bool = False, calculate_token_accuracy: bool = False):\n",
    "    \"\"\"\n",
    "    Runs one validation epoch (processing the entire validation dataset once). \n",
    "\n",
    "    Uses Teacher Forcing (i.e. \"gold\") to evaluate token-to-token mapping quality and for parallelization.\n",
    "\n",
    "    Args:\n",
    "        dataloader - The dataloader to process the dataset in BATCH_SIZE batches\n",
    "        model - The Encoder-Decoder that is being trained\n",
    "        loss_fn - The loss function to calculate the model's correctness\n",
    "        calculate_sequence_accuracy - A flag to mark whether sequence-level correctness should be tracked\n",
    "        calculate_token_accuracy - A flag to mark whether token-level correctness should be tracked\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    num_sequences = len(dataloader.dataset)\n",
    "    num_tokens = 0\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    total_correct_sequences = 0\n",
    "    total_correct_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (source, target), label in tqdm(dataloader):\n",
    "            \n",
    "            # FORWARD\n",
    "            pred_logits = model(source, target)\n",
    "            batch_loss = loss_fn(pred_logits.view(-1, pred_logits.size(-1)), label.view(-1))\n",
    "\n",
    "            # LOG\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            predictions = torch.argmax(pred_logits, dim = -1) # predictions.shape: [batch_size, seq_len]\n",
    "            match_matrix = torch.eq(predictions, label)\n",
    "\n",
    "            if calculate_sequence_accuracy:\n",
    "                num_correct_sequences = torch.all(match_matrix, dim = 1).sum()\n",
    "                total_correct_sequences += num_correct_sequences.item()\n",
    "\n",
    "            if calculate_token_accuracy:\n",
    "                num_correct_tokens = match_matrix.sum()      \n",
    "                total_correct_tokens += num_correct_tokens.item()\n",
    "\n",
    "                num_tokens += torch.numel(label)\n",
    "\n",
    "    average_epoch_loss = epoch_loss / num_sequences\n",
    "    average_epoch_sequence_accuracy = total_correct_sequences / num_sequences if calculate_sequence_accuracy else None\n",
    "    average_epoch_token_accuracy = total_correct_tokens / num_tokens if calculate_token_accuracy else None\n",
    "\n",
    "    return average_epoch_loss, average_epoch_sequence_accuracy, average_epoch_token_accuracy\n",
    "\n",
    "def run_autoregressive_validation_loop(dataloader: DataLoader, model: nn.Module):\n",
    "    \"\"\"\n",
    "    Runs one autoregressive validation epoch (processing the entire validation dataset once). \n",
    "\n",
    "    Args:\n",
    "        dataloader - The dataloader to process the dataset in BATCH_SIZE batches\n",
    "        model - The Encoder-Decoder that is being trained\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    correct_sequences = 0\n",
    "    incorrect_sequences = 0\n",
    "    total_sequences = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (source, _), label in tqdm(dataloader):\n",
    "\n",
    "            # FORWARD\n",
    "            pred_indices, pred_logits = greedy_decode(source, model)\n",
    "\n",
    "            np_source_indices = source.numpy().copy()\n",
    "            np_pred_target_indices = pred_indices.numpy().copy()\n",
    "\n",
    "            token_values = np.array(list(VOCAB_MAP.values()))\n",
    "            predicted_source_tokens = token_values[np_source_indices]\n",
    "            predicted_target_tokens = token_values[np_pred_target_indices]\n",
    "\n",
    "            for s, t in zip(predicted_source_tokens, predicted_target_tokens):\n",
    "                source_end_index = np.argmax(s == '<PAD>')  if '<PAD>' in s else len(s)\n",
    "                target_end_index = np.argmax(t == '<EOS>')\n",
    "                if np.array_equal(np.sort(s[:source_end_index]), t[1:target_end_index]):\n",
    "                    correct_sequences += 1\n",
    "                else:\n",
    "                    incorrect_sequences += 1\n",
    "                    print(f'Incorrect Sequence {incorrect_sequences}:')\n",
    "                    print(np.sort(s[:source_end_index]))\n",
    "                    print(t[1:target_end_index])\n",
    "                    print(f'{'Source:':<20} {s}\\n{'Predicted Target:':<20} {t}', end = '\\n\\n')\n",
    "\n",
    "            total_sequences += predicted_target_tokens.shape[0]\n",
    "\n",
    "    return correct_sequences / total_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:08<00:00, 17.72it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.09it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.25it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.03it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 18.97it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.01it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.08it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.86it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.29it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.49it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.33it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.22it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.46it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.02it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 18.92it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 52.64it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.11it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 54.48it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.08it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.9956224903106685, 1.8113396434783935, 0.9595275775909424, 0.5739403173804283, 0.5067678166747093, 0.8473928666114807, 0.08300657985210419, 0.03322321484088898, 0.7289299174726009, 0.05126665424108505]\n",
      "[0.0028, 0.0159, 0.0256, 0.0348, 0.0365, 0.0317, 0.0515, 0.0541, 0.037, 0.0533]\n",
      "[0.4620571504924792, 0.5423993058204287, 0.5557701846764347, 0.5625143129770992, 0.5633957840969734, 0.5578385952871197, 0.5699454697986577, 0.5706679389312977, 0.5614829245931698, 0.5704603556166056]\n",
      "\n",
      "[9.56902621459961, 0.8637341880798339, 3.5278837890625, 2.544419677734375, 0.14738343524932862, 0.30951369285583497, 0.038920241713523866, 0.03802552580833435, 0.12167732405662536, 0.0335579354763031]\n",
      "[0.0, 0.021, 0.0, 0.0, 0.039, 0.045, 0.049, 0.048, 0.047, 0.049]\n",
      "[0.4338937714940772, 0.5480989682842949, 0.5136606801681315, 0.5250286587695835, 0.559849063813527, 0.5585594191822698, 0.5611864730607566, 0.5610909438288116, 0.5605177684371417, 0.5611864730607566]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "training_losses = list()\n",
    "training_sequence_accuracies = list()\n",
    "training_token_accuracies = list()\n",
    "\n",
    "gold_validation_losses = list()\n",
    "gold_validation_sequence_accuracies = list()\n",
    "gold_validation_token_accuracies = list()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    # print(f'Running epoch {i+1}...')\n",
    "\n",
    "    training_loss, training_sequence_accuracy, training_token_accuracy = run_train_epoch(train_dataloader, model, loss_fn, optim, calculate_sequence_accuracy = True, calculate_token_accuracy = True)\n",
    "\n",
    "    training_losses.append(training_loss)\n",
    "    training_sequence_accuracies.append(training_sequence_accuracy)\n",
    "    training_token_accuracies.append(training_token_accuracy)\n",
    "\n",
    "    gold_val_loss, gold_val_sequence_accuracy, gold_val_token_accuracy = run_gold_validation_loop(val_dataloader, model, loss_fn, calculate_sequence_accuracy = True, calculate_token_accuracy = True)\n",
    "    \n",
    "    gold_validation_losses.append(gold_val_loss)\n",
    "    gold_validation_sequence_accuracies.append(gold_val_sequence_accuracy)\n",
    "    gold_validation_token_accuracies.append(gold_val_token_accuracy)\n",
    "\n",
    "print(training_losses)\n",
    "print(training_sequence_accuracies)\n",
    "print(training_token_accuracies)\n",
    "\n",
    "print()\n",
    "\n",
    "print(gold_validation_losses)\n",
    "print(gold_validation_sequence_accuracies)\n",
    "print(gold_validation_token_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [00:00<00:05,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sequence 1:\n",
      "['0' '0' '0' '0' '0' '0' '0' '2' '3' '3' '7' '7' '7' '9' '9' '9' '9' '9'\n",
      " '9' '9']\n",
      "[]\n",
      "Source:              ['9' '3' '0' '0' '2' '9' '9' '9' '7' '0' '9' '9' '7' '7' '9' '0' '0' '0'\n",
      " '0' '3']\n",
      "Predicted Target:    ['<SOS>' '0' '0' '0' '0' '0' '0' '0' '2' '3' '3' '7' '7' '7' '9' '9' '9'\n",
      " '9' '9' '9' '0' '0' '0' '0' '0' '0' '0' '0' '0' '7' '7' '7' '7' '7' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      "\n",
      "Incorrect Sequence 2:\n",
      "['1' '1' '3' '3' '3' '3' '3' '3' '4' '5' '7' '9' '9' '9' '9' '9']\n",
      "['1' '1' '3' '3' '3' '3' '3' '3' '4' '5' '7' '9' '9' '9' '9']\n",
      "Source:              ['9' '1' '9' '3' '3' '3' '9' '1' '9' '3' '3' '5' '3' '9' '7' '4' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>']\n",
      "Predicted Target:    ['<SOS>' '1' '1' '3' '3' '3' '3' '3' '3' '4' '5' '7' '9' '9' '9' '9'\n",
      " '<EOS>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [00:01<00:02,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sequence 3:\n",
      "['0' '0' '0' '0' '0' '0' '3' '3' '3' '4' '4' '4' '5' '6' '7' '7' '8' '9'\n",
      " '9']\n",
      "['0' '0' '0' '0' '0' '3' '3' '3' '4' '4' '4' '5' '6' '7' '7' '8' '9' '9']\n",
      "Source:              ['3' '4' '8' '0' '0' '5' '9' '0' '0' '4' '0' '0' '9' '6' '3' '7' '4' '3'\n",
      " '7' '<PAD>']\n",
      "Predicted Target:    ['<SOS>' '0' '0' '0' '0' '0' '3' '3' '3' '4' '4' '4' '5' '6' '7' '7' '8'\n",
      " '9' '9' '<EOS>' '<PAD>' '<PAD>']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [00:01<00:01,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sequence 4:\n",
      "['0' '1' '1' '1' '3' '4' '4' '4' '5' '5' '5' '5' '7' '7' '7' '7' '7' '8'\n",
      " '8']\n",
      "['0' '1' '1' '1' '3' '4' '4' '4' '5' '5' '5' '5' '7' '7' '7' '7' '8' '8']\n",
      "Source:              ['1' '5' '4' '1' '4' '0' '3' '7' '1' '7' '5' '7' '7' '7' '8' '8' '4' '5'\n",
      " '5' '<PAD>']\n",
      "Predicted Target:    ['<SOS>' '0' '1' '1' '1' '3' '4' '4' '4' '5' '5' '5' '5' '7' '7' '7' '7'\n",
      " '8' '8' '<EOS>' '<PAD>' '<PAD>']\n",
      "\n",
      "Incorrect Sequence 5:\n",
      "['1' '1' '2' '3' '5' '5' '5' '5' '5' '6' '6' '6' '9' '9']\n",
      "['1' '1' '2' '3' '5' '5' '5' '5' '6' '6' '6' '9' '9']\n",
      "Source:              ['5' '2' '5' '5' '9' '5' '9' '1' '1' '6' '5' '6' '6' '3' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "Predicted Target:    ['<SOS>' '1' '1' '2' '3' '5' '5' '5' '5' '6' '6' '6' '9' '9' '<EOS>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [00:02<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sequence 6:\n",
      "['2' '7' '7' '8' '8' '8' '8' '9' '9' '9']\n",
      "['2' '7' '8' '8' '8' '9' '9']\n",
      "Source:              ['9' '9' '8' '7' '2' '9' '8' '8' '7' '8' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>']\n",
      "Predicted Target:    ['<SOS>' '2' '7' '8' '8' '8' '9' '9' '<EOS>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>' '<PAD>'\n",
      " '<PAD>']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = run_autoregressive_validation_loop(val_dataloader, model)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
